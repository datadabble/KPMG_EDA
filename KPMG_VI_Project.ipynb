{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Store Data Quality Assessment\n",
    "### This is to analyze the data from the Bike Store to confirm its quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "#reads excel workbook into workable python format\n",
    "df_CustDem = pd.ExcelFile('KPMG_VI_Data_Set.xlsx').parse('CustomerDemographic', header=1, index_col=0)\n",
    "df_Transactions = pd.ExcelFile('KPMG_VI_Data_Set.xlsx').parse('Transactions', header=1)\n",
    "df_NewCust = pd.ExcelFile('KPMG_VI_Data_Set.xlsx').parse('NewCustomerList', header=1)\n",
    "df_Address = pd.ExcelFile('KPMG_VI_Data_Set.xlsx').parse('CustomerAddress', header=1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review and Clean\n",
    "### Customer Demographic DataFrame\n",
    "    Explore Customer Demographic dataframe and note inconsistencies and points of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4000 entries, 1 to 4000\n",
      "Data columns (total 12 columns):\n",
      " #   Column                               Non-Null Count  Dtype         \n",
      "---  ------                               --------------  -----         \n",
      " 0   first_name                           4000 non-null   string        \n",
      " 1   last_name                            3875 non-null   string        \n",
      " 2   gender                               4000 non-null   string        \n",
      " 3   past_3_years_bike_related_purchases  4000 non-null   Int64         \n",
      " 4   DOB                                  3913 non-null   datetime64[ns]\n",
      " 5   job_title                            3494 non-null   string        \n",
      " 6   job_industry_category                3344 non-null   string        \n",
      " 7   wealth_segment                       4000 non-null   string        \n",
      " 8   deceased_indicator                   4000 non-null   string        \n",
      " 9   default                              3698 non-null   object        \n",
      " 10  owns_car                             4000 non-null   string        \n",
      " 11  tenure                               3913 non-null   Int64         \n",
      "dtypes: Int64(2), datetime64[ns](1), object(1), string(8)\n",
      "memory usage: 414.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#dataframe values were previously listed as objects, covert_dtypes converts into correct data types\n",
    "df_CustDem = df_CustDem.convert_dtypes()\n",
    "df_CustDem.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_name                                          Zulema\n",
       "gender                                                   U\n",
       "past_3_years_bike_related_purchases                     99\n",
       "DOB                                    2002-03-11 00:00:00\n",
       "wealth_segment                               Mass Customer\n",
       "deceased_indicator                                       Y\n",
       "owns_car                                               Yes\n",
       "dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CustDem.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_name                                          Aarika\n",
       "gender                                                   F\n",
       "past_3_years_bike_related_purchases                      0\n",
       "DOB                                    1843-12-21 00:00:00\n",
       "wealth_segment                           Affluent Customer\n",
       "deceased_indicator                                       N\n",
       "owns_car                                                No\n",
       "dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CustDem.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reviewing the min and max of values in each column we can see problems with the data. \n",
    "For example: one customer had 99 bike purchases within the last three years. This would be cause for further exploration. \n",
    "The gender column also has an unusal value in it that requires further understanding.\n",
    "In the min exploration we can see that one cutomer was born in 1843- more likely a mistake than a customer is 178 years old.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    2037\n",
       "Male      1872\n",
       "U           88\n",
       "F            1\n",
       "Femal        1\n",
       "M            1\n",
       "Name: gender, dtype: Int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CustDem['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "88 rows have the value U in the gender column- need clarification if it stands for Unanswered or a nonbinary answer. 2 values also need to be standardized from F and M to Female and Male. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mass Customer        2000\n",
       "High Net Worth       1021\n",
       "Affluent Customer     979\n",
       "Name: wealth_segment, dtype: Int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CustDem['wealth_segment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column might be significant to examine more closely. What are the parameters that determine a Mass Customer from and High Net Worth and Affluent Customer? \n",
    "It is also important to note that the Mass Customer is 50% of the customer base. But which customer category produces the most revenue for the business?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wealth_segment\n",
       "Affluent Customer    47822\n",
       "High Net Worth       48281\n",
       "Mass Customer        99457\n",
       "Name: past_3_years_bike_related_purchases, dtype: Int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of total bikes purchased by each group\n",
    "purchased_group = df_CustDem.groupby('wealth_segment')\n",
    "purchased_group['past_3_years_bike_related_purchases'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these two explorations we can see that not only is the Mass Customer group the largest percentage of customers, they also acount for almost 50% of bike purchases in the last 3 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_name                               0\n",
       "last_name                              125\n",
       "gender                                   0\n",
       "past_3_years_bike_related_purchases      0\n",
       "DOB                                     87\n",
       "job_title                              506\n",
       "job_industry_category                  656\n",
       "wealth_segment                           0\n",
       "deceased_indicator                       0\n",
       "default                                302\n",
       "owns_car                                 0\n",
       "tenure                                  87\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find amount of null values in each column\n",
    "df_CustDem.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customer Demographic Summary\n",
    "From this we can tell that there are several inconsistaencies and missing values in the data. desicion will be to determine if we can remove those columns from analysis or input replacement data. \n",
    "We also determined that several values were entered incorrectly and nest steps could be to remove those rows from the data. \n",
    "However prelimerary conclsuions can be made that the Mass customer group is responsible for 50% of bike pruchases and its cutomer base. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   transaction_id           20000 non-null  Int64         \n",
      " 1   product_id               20000 non-null  Int64         \n",
      " 2   customer_id              20000 non-null  Int64         \n",
      " 3   transaction_date         20000 non-null  datetime64[ns]\n",
      " 4   online_order             19640 non-null  Int64         \n",
      " 5   order_status             20000 non-null  string        \n",
      " 6   brand                    19803 non-null  string        \n",
      " 7   product_line             19803 non-null  string        \n",
      " 8   product_class            19803 non-null  string        \n",
      " 9   product_size             19803 non-null  string        \n",
      " 10  list_price               20000 non-null  float64       \n",
      " 11  standard_cost            19803 non-null  float64       \n",
      " 12  product_first_sold_date  19803 non-null  Int64         \n",
      "dtypes: Int64(5), datetime64[ns](1), float64(2), string(5)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_Transactions = df_Transactions.convert_dtypes()\n",
    "df_Transactions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the meta data of this dataframe we can see the there are several missing values in 7 of the columns. 6 of those have the same number of missing values. We can also see that even though there are two columns referencing dates, only one is formatted in a datefime format. \n",
    "We will explore these issues more below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id               0\n",
       "product_id                   0\n",
       "customer_id                  0\n",
       "transaction_date             0\n",
       "online_order               360\n",
       "order_status                 0\n",
       "brand                      197\n",
       "product_line               197\n",
       "product_class              197\n",
       "product_size               197\n",
       "list_price                   0\n",
       "standard_cost              197\n",
       "product_first_sold_date    197\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id                        1\n",
       "product_id                            0\n",
       "customer_id                           1\n",
       "transaction_date    2017-01-01 00:00:00\n",
       "order_status                   Approved\n",
       "list_price                        12.01\n",
       "standard_cost                      7.21\n",
       "dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Transactions.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id                    20000\n",
       "product_id                          100\n",
       "customer_id                        5034\n",
       "transaction_date    2017-12-30 00:00:00\n",
       "order_status                  Cancelled\n",
       "list_price                      2091.47\n",
       "standard_cost                   1759.85\n",
       "dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Transactions.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First steps we can tell that there are 11 columns and of those, online_orders has the most null values. the remaining 6 columns with null values all have the same amount of 197. Such uniformity among all 6 columns causes further investigation. \n",
    "Next we check for outliers by looking at the min and max values of each column. Of immediate interest is the large differece between list price: lowest at $12.01 and max of $2,091.47 confirming accurancy of those amounts is neccessary to validate. \n",
    "Second if the date. The transaction data was to be for three months but the earliest is January 1, 2017 and the latest December 30, 2017. That is a year versus a three month review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium    12990\n",
       "large      3976\n",
       "small      2837\n",
       "Name: product_size, dtype: Int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Transactions['order_status'].value_counts()\n",
    "df_Transactions['product_line'].value_counts()\n",
    "df_Transactions['product_class'].value_counts()\n",
    "df_Transactions['product_size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing some of the columns cotaining strings to confirmed values were uniform buy counting the unique values in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2017-02-25\n",
       "1   2017-05-21\n",
       "2   2017-10-16\n",
       "3   2017-08-31\n",
       "4   2017-10-01\n",
       "Name: transaction_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Transactions['transaction_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    41245\n",
       "1    41701\n",
       "2    36361\n",
       "3    36145\n",
       "4    42226\n",
       "Name: product_first_sold_date, dtype: Int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Transactions['product_first_sold_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1970-01-01 00:00:00.000041245\n",
       "1   1970-01-01 00:00:00.000041701\n",
       "2   1970-01-01 00:00:00.000036361\n",
       "3   1970-01-01 00:00:00.000036145\n",
       "4   1970-01-01 00:00:00.000042226\n",
       "Name: product_first_sold_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Transactions['product_first_sold_date'] = df_Transactions['product_first_sold_date'].fillna(0).astype('datetime64[ns]', errors='ignore')\n",
    "df_Transactions['product_first_sold_date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transaction Dataframe Summary\n",
    "There are 197 null values in 6 columns and one column has 360 null values. The decision needs to be made to eithe remove the rows or columns from analysis are replace the nulls with alternative values. \n",
    "There are two columns that should be in a datetime format however the product sold date column is an integer format.\n",
    "Several efforts to convert the integers in Product_first_sold column to datetime objects were unsuccessful. However it should be noted that when accessing the data in excel the conversion can be made, but the inconsisentacy does raise the question of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Address Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   customer_id         3999 non-null   Int64 \n",
      " 1   address             3999 non-null   string\n",
      " 2   postcode            3999 non-null   Int64 \n",
      " 3   state               3999 non-null   string\n",
      " 4   country             3999 non-null   string\n",
      " 5   property_valuation  3999 non-null   Int64 \n",
      "dtypes: Int64(3), string(3)\n",
      "memory usage: 199.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_Address = df_Address.convert_dtypes()\n",
    "df_Address.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance this dataset looks to be complete, no null values and datatype appears to align correctly with the column names. Next we will see if there are any repeat values in the customer_id column and the address and postcode columns to confrim no customer was entered twice. We will also look into the property_valuation column more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3999\n",
       "Name: customer_id, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Address['customer_id'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      customer_id                  address  postcode state    country  \\\n",
      "2470         2475         3 Talisman Place      4017   QLD  Australia   \n",
      "2980         2985  3 Mariners Cove Terrace      2216   NSW  Australia   \n",
      "3535         3540   64 Macpherson Junction      4061   QLD  Australia   \n",
      "\n",
      "      property_valuation  \n",
      "2470                   5  \n",
      "2980                  10  \n",
      "3535                   8  \n"
     ]
    }
   ],
   "source": [
    "df_Address['address'].duplicated().sum()\n",
    "dup_address = df_Address[df_Address['address'].duplicated()]\n",
    "print(dup_address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     647\n",
       "8     646\n",
       "10    577\n",
       "7     493\n",
       "11    281\n",
       "6     238\n",
       "5     225\n",
       "4     214\n",
       "12    195\n",
       "3     186\n",
       "1     154\n",
       "2     143\n",
       "Name: property_valuation, dtype: Int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Address['property_valuation'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customer Address Dataframe Summary\n",
    "Although there are no repeated customer ids, we do have three repeated addresses which could mean more than one customer at the same address or a duplicated address created for the same customer. \n",
    "upon investigation we were also able to see that property_valuation is broken up into 12 categories with the top valuations being 9, 8, and 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Assessment Summary\n",
    "Below is a summary of the quality assessment of each dataset. \n",
    "\n",
    "#### Customer Demographic dataset\n",
    "When reviewing the min and max of values in each column we can see problems with the data. For example: one customer had 99 bike purchases within the last three years. This would be cause for further exploration. And in theDOB column we can see that one cutomer was born in 1843- more likely a mistake than a customer is 178 years old. The gender column has 88 rows have the value U. Does this stand for Unanswered or a nonbinary? Needs clarification. 2 values also need to be standardized from F and M to Female and Male. The welth segment column might be significant to examine more closely. What are the parameters that determine a Mass Customer from and High Net Worth and Affluent Customer? It is also important to note that the Mass Customer is 50% of the customer base. When reviewing wealth segment with bike purchases we can see that not only is the Mass Customer group the largest percentage of customers, they also acount for almost 50% of bike purchases in the last 3 years. \n",
    "#### Transaction dataset\n",
    "When looking at the meta data of this dataset we can see the there are several missing values in 7 of the columns. 6 of those columns have 197 null values and the othe 360. We can also see that even though there are two columns referencing dates, only one is formatted in a datetime format. Several efforts were made to convert the integer values of the product_sold_date column to no success. Of the 11 columns, online_orders has the most null values. the remaining 6 columns with null values all have the same amount of 197. Such uniformity among all 6 columns causes further investigation. Next we check for outliers by looking at the min and max values of each column. Of immediate interest is the large differece between list price: lowest at  12.01 and max of 2,091.47 confirming accurancy of those amounts is neccessary to validate. Another thing to note is the transaction data was to be for three monthsm but the earliest is January 1, 2017 and the latest December 30, 2017. That is a year versus a three month review.\n",
    "#### Customer Address dataset\n",
    "At first glance this dataset looks to be complete, no null values and datatype appears to align correctly with the column names. Although there are no repeated customer ids, we do have three repeated addresses which could mean more than one customer at the same address or a duplicated address created for the same customer. Upon investigation we were also able to see that property_valuation is broken up into 12 categories with the top valuations being 9, 8, and 10.\n",
    "\n",
    "#### Conclusion\n",
    "What we can see from looking into the data is that there are some inconsistencies and discrepincies with the three datasets. In particular the customer demographic and transaction data sets. Several descions need to be made about whether to omit the rows and columns containing the large amount of null values before any significant analysis can be done. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
